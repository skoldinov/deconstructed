{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69c8cf40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T17:43:41.882483Z",
     "start_time": "2023-06-02T17:43:41.868609Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Iterable\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Using an extended version of Karpathy's micrograd library to work with gradients. Thanks Andrej!  \n",
    "from micrograd.engine import Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb913ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T18:08:59.630486Z",
     "start_time": "2023-06-02T18:08:59.439432Z"
    }
   },
   "outputs": [],
   "source": [
    "news_df_train = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5eea2f90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T18:09:03.032141Z",
     "start_time": "2023-06-02T18:08:59.631457Z"
    }
   },
   "outputs": [],
   "source": [
    "news_df_train['data_preprocessed'] = []\n",
    "\n",
    "for document in news_df_train['data']:\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(document))    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "    news_df_train['data_preprocessed'].append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9568f92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T18:09:03.048240Z",
     "start_time": "2023-06-02T18:09:03.033143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'data_preprocessed'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e42768e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T18:09:05.637245Z",
     "start_time": "2023-06-02T18:09:05.629237Z"
    }
   },
   "outputs": [],
   "source": [
    "# news_df_train['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a8b20d1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T18:37:33.017254Z",
     "start_time": "2023-06-02T18:37:32.998122Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "class Word2Vec():\n",
    "    def __init__(self, \n",
    "                 sentences: List[List[str]],\n",
    "                 embedding_dim: int,\n",
    "                 learning_rate: float,\n",
    "                 batch_size: int,\n",
    "                 window_size: int\n",
    "                ):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        # Dicts that store word-to-index and index-to-word pairs  \n",
    "        self.wtoi = {}\n",
    "        self.itow = {}\n",
    "        self.words = []\n",
    "        \n",
    "        self.generate_dictionary(sentences)\n",
    "        self.vocab_size = len(self.wtoi)\n",
    "        # Initiate context vector and word vector matrices randomly (?)\n",
    "        self.context_vectors = np.random.rand(self.vocab_size, embedding_dim)\n",
    "        self.word_vectors = np.random.rand(self.vocab_size, embedding_dim)\n",
    "\n",
    "    # Iterate over corpus and fill dictionary\n",
    "    def generate_dictionary(self,\n",
    "                            sentences: List[List[str]]):\n",
    "        count = 0 \n",
    "        for row in sentences:\n",
    "            for word in row:\n",
    "                word = word.lower()\n",
    "                self.words.append(word)\n",
    "                \n",
    "            if self.wtoi.get(word) == None:\n",
    "                self.wtoi.update({word : count})\n",
    "                self.itow.update({count : word})\n",
    "                count += 1\n",
    "                \n",
    "#     def get_vector(self, word):\n",
    "        \n",
    "    # Train by adjusting the word vectors \n",
    "#     def train(self):\n",
    "#         for sentence in sentences: \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    def predict(self,\n",
    "                sample: Iterable):\n",
    "        distances = [] \n",
    "        for idx, item in enumerate(self.data):\n",
    "            distances.append((idx, self.dist(item, sample))) \n",
    "        distances.sort(key=lambda x: x[1])\n",
    "        k_indices = [x[0] for x in distances[:self.k]]\n",
    "        k_labels = self.labels[k_indices]\n",
    "        pred = mode(k_labels)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5325c46e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T18:33:29.453007Z",
     "start_time": "2023-06-02T18:33:29.363668Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'sentences': news_df_train['data_preprocessed'][:10],\n",
    "    'embedding_dim': 300,\n",
    "    'window_size': 5,\n",
    "    'learning_rate': 0.01,\n",
    "    'batch_size': 10\n",
    "}\n",
    "\n",
    "w2v = Word2Vec(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876a575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6c0df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
